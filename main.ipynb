{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adds columns for previous week and previous week year to the dataframe\n",
    "\"\"\"\n",
    "def preprocess_features(features: pl.DataFrame) -> pl.DataFrame:\n",
    "    delta_in_weeks = 3\n",
    "    features = features.with_columns(\n",
    "        ((pl.col(\"week_start_date\").cast(pl.Date) \n",
    "         + timedelta(weeks=delta_in_weeks)).dt.year()).alias(\"next_week_year\"))\n",
    "    \n",
    "    features = features.with_columns(\n",
    "        (((pl.col(\"week_start_date\").cast(pl.Date) \n",
    "           + timedelta(weeks=delta_in_weeks)).dt.week())).alias(\"next_weekofyear\"))\n",
    "    \n",
    "    # cyclical encode week of year\n",
    "    max_week_value = 52\n",
    "    features = features.with_columns(\\\n",
    "        weekofyear_encoded=(pl.Expr.sin(2 * math.pi * pl.col(\"weekofyear\") / max_week_value)))\n",
    "\n",
    "    features = features.with_columns(\\\n",
    "        ndvi_aggregate=pl.col(\"ndvi_ne\") + pl.col(\"ndvi_nw\") + pl.col(\"ndvi_se\") + pl.col(\"ndvi_sw\"))\n",
    "\n",
    "    return (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(city):\n",
    "    # build the training data set\n",
    "    q = (\n",
    "        pl.scan_csv(\"data/dengue_features_train.csv\")\n",
    "        .filter(pl.col(\"city\") == city)\n",
    "    )\n",
    "    train_features = q.collect()\n",
    "    train_features = preprocess_features(train_features)\n",
    "\n",
    "    q = (\n",
    "        pl.scan_csv(\"data/dengue_labels_train.csv\")\n",
    "        .filter(pl.col(\"city\") == city)\n",
    "    )\n",
    "    train_labels = q.collect()\n",
    "\n",
    "    train_features_and_labels = train_features.join(\n",
    "        train_labels, left_on=['city', 'next_week_year', 'next_weekofyear'], \n",
    "        right_on=['city', 'year', 'weekofyear'], how='inner')\n",
    "    \n",
    "    train_features_and_labels = train_features_and_labels.fill_nan(None)\n",
    "    train_features_and_labels = train_features_and_labels\\\n",
    "        .fill_null(strategy=\"forward\")\n",
    "    train_features_and_labels = train_features_and_labels.with_columns(\n",
    "        weekofyear_historical_average_total_cases = \n",
    "        pl.col(\"total_cases\").mean().over(pl.col(\"weekofyear\"))\n",
    "    )\n",
    "    \n",
    "    selected_feature_names = [\n",
    "        \"weekofyear_encoded\",\n",
    "        \"weekofyear_historical_average_total_cases\",\n",
    "        \"reanalysis_specific_humidity_g_per_kg\",\n",
    "        \"reanalysis_dew_point_temp_k\",\n",
    "        \"station_avg_temp_c\",\n",
    "        \"station_min_temp_c\"\n",
    "    ]\n",
    "\n",
    "    # corr = train_features_and_labels[selected_feature_names].corr()\n",
    "    # print(corr[\"total_cases\"])\n",
    "    # return\n",
    "\n",
    "    # train the model\n",
    "    split_training_set = False\n",
    "    X = train_features_and_labels[selected_feature_names]\n",
    "    y = train_features_and_labels[\"total_cases\"]\n",
    "\n",
    "    train_len = X.shape[0]\n",
    "    if split_training_set:\n",
    "        train_len = math.ceil(3/4 * X.shape[0])\n",
    "\n",
    "    X_train, X_test = X[:train_len], X[train_len:]\n",
    "    y_train, y_test = y[:train_len], y[train_len:]\n",
    "    clf = HistGradientBoostingRegressor(max_iter=100).fit(X_train, y_train)\n",
    "\n",
    "    if split_training_set:\n",
    "        print(clf.score(X_test, y_test))\n",
    "\n",
    "    # now make predictions on the test set\n",
    "    q = (\n",
    "        pl.scan_csv(\"data/dengue_features_test.csv\")\n",
    "        .filter(pl.col(\"city\") == city)\n",
    "    )\n",
    "    test_features = q.collect()\n",
    "    test_features = preprocess_features(test_features)\n",
    "    test_features = test_features.join(train_features_and_labels.drop(\"total_cases\"), how=\"left\", on=[\"year\", \"weekofyear\"], maintain_order=\"left\")\n",
    "\n",
    "    y_pred = clf.predict(test_features[selected_feature_names]).clip(min=0)\n",
    "    result = pl.concat([test_features, \n",
    "                     pl.DataFrame({\"total_cases\": y_pred.round().astype(int)})], how=\"horizontal\")\n",
    "    \n",
    "    return result['city', 'year', 'weekofyear', 'total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_predictions = get_predictions(\"sj\")\n",
    "iq_predictions = get_predictions(\"iq\")\n",
    "pl.concat([sj_predictions, iq_predictions], how=\"vertical\").write_csv(\n",
    "    \"data/output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
