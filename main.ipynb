{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "generate_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd748e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(weekofyear: int, nothern_hemisphere: bool=True) -> str:\n",
    "    season = \"unknown\"\n",
    "    \n",
    "    if weekofyear in range(1, 10) or weekofyear in range(50, 53):\n",
    "        if nothern_hemisphere:\n",
    "            season = \"winter\"\n",
    "        else:\n",
    "            season = \"summer\"\n",
    "    elif weekofyear in range(10, 22):\n",
    "        if nothern_hemisphere:\n",
    "            season = \"spring\"\n",
    "        else:\n",
    "            season = \"fall\"\n",
    "    elif weekofyear in range(22, 35):\n",
    "        if nothern_hemisphere:\n",
    "            season = \"summer\"\n",
    "        else:\n",
    "            season = \"winter\"\n",
    "    elif weekofyear in range(35, 50):\n",
    "        if nothern_hemisphere:\n",
    "            season = \"fall\"\n",
    "        else:\n",
    "            season = \"spring\"\n",
    "\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a9d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(features: pl.DataFrame) -> pl.DataFrame:\n",
    "    features = features.fill_nan(None)\n",
    "    features = features.fill_null(strategy=\"forward\")\n",
    "    features = features.sort(\"week_start_date\")\n",
    "    \n",
    "    num_weeks_backward_to_look = 8\n",
    "    feature_columns = features.columns[4:]\n",
    "    for i in range(1, num_weeks_backward_to_look + 1):\n",
    "        for feature in feature_columns:\n",
    "            features = features.with_columns(\n",
    "                pl.col(feature).shift(i).alias(f\"{feature}_weekminus{i}\"))\n",
    "    features = features.fill_null(strategy=\"backward\")\n",
    "\n",
    "    features = features.with_columns(\n",
    "        season=pl.struct(\"weekofyear\", \"city\")\n",
    "        .map_elements(lambda cols: get_season(cols[\"weekofyear\"], cols[\"city\"]==\"sj\"), return_dtype=pl.String))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns something like {'l2_regularization': 0.1, 'learning_rate': 0.01, 'max_depth': 3, 'max_iter': 100}\n",
    "\"\"\"\n",
    "def get_best_hyperparameters(model, X_train, y_train):\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_iter': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'l2_regularization': [0.0, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    # Define the scoring metric\n",
    "    scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "    # Define the grid search\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and score, Negate for MSE\n",
    "    return  grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(city):\n",
    "    # build the training data set\n",
    "    q = (\n",
    "        pl.scan_csv(\"data/dengue_features_train.csv\")\n",
    "        .filter(pl.col(\"city\") == city)\n",
    "    )\n",
    "    features_train = q.collect()\n",
    "    original_columns = features_train.columns[4:]\n",
    "    features_train = preprocess_data(features_train)\n",
    "\n",
    "    q = (\n",
    "        pl.scan_csv(\"data/dengue_labels_train.csv\")\n",
    "        .filter(pl.col(\"city\") == city)\n",
    "    )\n",
    "    labels_train = q.collect()\n",
    "\n",
    "    features_and_labels_train = features_train.join(\n",
    "        labels_train, left_on=['city', 'year', 'weekofyear'], \n",
    "        right_on=['city', 'year', 'weekofyear'], how='inner')\n",
    "    \n",
    "    # pick features with best correlation to total cases\n",
    "    features_to_correlate = [col for col in features_and_labels_train.columns \n",
    "                             if col not in [\"city\", \"year\", \"weekofyear\", \"week_start_date\", \"season\"]]\n",
    "    corr = features_and_labels_train[features_to_correlate].corr()\n",
    "    corr_column_df = pl.DataFrame({ \"columns\": corr.columns})\n",
    "    corr = pl.concat([corr, corr_column_df], how=\"horizontal\")\n",
    "    corr = corr[[\"columns\", \"total_cases\"]]\n",
    "\n",
    "    best_feature_columns = []\n",
    "    for column in original_columns:\n",
    "        filtered_columns = corr.filter(pl.col(\"columns\").str.contains(column))\n",
    "        best_corr = filtered_columns.select(pl.max(\"total_cases\")).item()\n",
    "        if best_corr >= 0.3:\n",
    "            best_feature_column = filtered_columns.filter(\n",
    "                pl.col(\"total_cases\") == best_corr).select(\"columns\").item()\n",
    "            best_feature_columns.append(best_feature_column)\n",
    "    \n",
    "    # limit the number of features used\n",
    "    best_feature_columns = best_feature_columns[:5]\n",
    "    best_feature_columns.append(\"weekofyear\")\n",
    "\n",
    "    # train the model\n",
    "    X = features_and_labels_train[best_feature_columns]\n",
    "    y = features_and_labels_train[\"total_cases\"]\n",
    "\n",
    "    train_len = X.shape[0]\n",
    "    if not generate_output:\n",
    "        train_len = math.ceil(3/4 * X.shape[0])\n",
    "\n",
    "    # pick best hyperparameters\n",
    "    clf = HistGradientBoostingRegressor(random_state=42, categorical_features=[\"weekofyear\"])\n",
    "    best_params = get_best_hyperparameters(clf, X[:train_len], y[:train_len])\n",
    "    clf.set_params(l2_regularization=best_params[\"l2_regularization\"],\n",
    "                   learning_rate=best_params[\"learning_rate\"], \n",
    "                   max_depth=best_params[\"max_depth\"], \n",
    "                   max_iter=best_params[\"max_iter\"])\n",
    "    clf.fit(X[:train_len], y[:train_len])\n",
    "\n",
    "    if not generate_output:\n",
    "        score = clf.score(X[train_len:], y[train_len:])\n",
    "        print(f\"Training set score: {score}\")\n",
    "    \n",
    "    # now make predictions on the test set\n",
    "    q = (\n",
    "        pl.scan_csv(\"data/dengue_features_test.csv\")\n",
    "        .filter(pl.col(\"city\") == city)\n",
    "    )\n",
    "    features_test = q.collect()\n",
    "    features_test = preprocess_data(features_test)\n",
    "\n",
    "    y_pred = clf.predict(features_test[best_feature_columns]).clip(min=0)\n",
    "    result = pl.concat([features_test, \n",
    "                     pl.DataFrame({\"total_cases\": y_pred.round().astype(int)})], how=\"horizontal\")\n",
    "    \n",
    "    return result['city', 'year', 'weekofyear', 'total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_predictions = get_predictions(\"sj\")\n",
    "iq_predictions = get_predictions(\"iq\")\n",
    "\n",
    "if generate_output:\n",
    "    pl.concat([sj_predictions, iq_predictions], how=\"vertical\").write_csv(\n",
    "        \"data/output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
